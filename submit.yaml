description: self-preference

environment:
  image: amlt-sing/acpt-torch2.7.1-py3.10-cuda12.6-ubuntu22.04
  setup:
    - export PATH=$$PATH:/home/aiscuser/.local/bin
    - pip install packaging
    - pip install ninja
    - pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.0.post2/flash_attn-2.8.0.post2+cu12torch2.5cxx11abiFALSE-cp310-cp310-linux_x86_64.whl
    - pip install vllm
    - pip install onnxruntime-gpu
    - pip install datasets
    - pip install transformers
    - pip install python-dotenv
    - pip install uuid
    - pip install openai
    - pip install jsonlines
    - pip install tqdm
    - pip install pandas

code:
  local_dir: $CONFIG_DIR

target:
  service: sing
  name: msrresrchbasicvc 
  workspace_name: CS-NewsAndFeeds-Singularity

storage:
  external:
    storage_account_name: csnewsandfeeds4150361735
    container_name: unium
    mount_dir: /mnt/blob_output

jobs:
  - name: self-preference
    sku: 80G8-A100
    sla_tier: Standard
    command:
      - bash run-vllm-societal.sh google/gemma-3-4b-it 4 --dataset trans_seg
      - pkill -f 'vllm serve' || true
      - bash run-vllm-societal.sh google/gemma-3-12b-it 4 --dataset trans_seg
      - pkill -f 'vllm serve' || true
      - bash run-vllm-societal.sh google/gemma-3-27b-it 4 --dataset trans_seg
      - pkill -f 'vllm serve' || true
      - bash run-comparisons.sh
      - pkill -f 'vllm serve' || true
      - bash recognition.sh
      - pkill -f 'vllm serve' || true
      - bash recognition_triple.sh
      - pkill -f 'vllm serve' || true
      - bash comparison_triple.sh
      - pkill -f 'vllm serve' || true
    submit_args:
      env:
        DATASET: trans_seg
        BLOB_OUTPUT_PATH: /mnt/blob_output/v-junyichen/
        AMLT_DOCKERFILE_TEMPLATE: DEFAULT
        CUDA_LAUNCH_BLOCKING: 1
        MKL_SERVICE_FORCE_INTEL: 1
        HF_TOKEN: ${HF_TOKEN}
        # WANDB_API_KEY: $WANDB_API_KEY
